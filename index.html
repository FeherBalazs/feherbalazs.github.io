<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Balazs Feher, PhD</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Balazs Feher, PhD</h1>
            <p><strong>Contact:</strong> +44 77 8381 9609 | <a href="mailto:balazs.feher@neuralmachines.co.uk">balazs.feher@neuralmachines.co.uk</a> | <a href="https://github.com/FeherBalazs" target="_blank">github.com/FeherBalazs</a> | <a href="https://uk.linkedin.com/in/balazsfeheruk" target="_blank">linkedin.com/in/balazsfeheruk</a></p>
        </header>

        <section id="summary">
            <h2>Professional Summary</h2>
            <p>I am an experienced data scientist with a strong background in developing and implementing machine learning models across various industries. My recent role as Lead Data Scientist at Genpact/Arietta.ai involved developing and fine-tuning transformer-based NLP models, transitioning models from proof of concept to production, and collaborating with cross-functional teams. I have also worked at Philip Morris, HSBC, Vocalink/Mastercard, Royal Mail, Deloitte, and Wellcome Collection, where I developed predictive analytics, anomaly detection, and NLP solutions to improve business operations and compliance. With a Ph.D. from Saarland University and experience as a researcher and intern at various institutions, I bring a deep understanding of both theoretical and practical aspects of data science. My expertise includes supervised and unsupervised ML methods, clustering, predictive analytics, NLP, LLMs, and RAG.</p>
        </section>

        <section id="experience">
            <h2>Experience</h2>
            <div class="job">
                <h3>Senior Data Scientist</h3>
                <p><strong>Neural Machines - self-employed</strong> | Oct 2024 – Present</p>
                <ul>
                    <li>Developed LLMs with Retrieval Augmented Generation (RAG).</li>
                    <li>Fine-tuned open-source LLMs for custom applications.</li>
                    <li>Conducted independent research project on predictive coding, a neuroscience-inspired approach to machine learning with applications in generative models and neural networks.</li>
                    <li>Built and optimized predictive coding algorithms leveraging JAX and PyTorch.</li>
                    <li>Key technologies used: Python, JAX, PyTorch, Docker, AWS, LambdaLabs.</li>
                </ul>
            </div>
            <div class="job">
                <h3>Lead Data Scientist</h3>
                <p><strong>Genpact/Arietta.ai - Contract</strong> | Jun 2021 – Oct 2024</p>
                <ul>
                    <li>Transitioned traditional NLP models to large language model based information extraction pipelines (Meta Llama-2/3, AWS Bedrock, OpenAI, Claude Anthropic)</li>
                    <li>Developed and fine-tuned transformer-based NLP models for information extraction (named entity recognition), classification and similarity search</li>
                    <li>Transitioned models from proof of concept to production, optimising for high throughput inference (experimented with model quantisation techniques, model serving frameworks, etc.).</li>
                    <li>Conducted experiments to optimise model performance and fine-tune hyperparameters.</li>
                    <li>Designed and ran distributed model training on AWS.</li>
                    <li>Implemented best practices for model versioning, monitoring, and maintenance on AWS.</li>
                    <li>Applied visual and NLP based clustering for unstructured document segmentation</li>
                    <li>Fine tuned custom open source large language models, e.g llama-2, llama-3</li>
                    <li>Developed custom inference pipeline scripts with transformers, Pytorch, Huggingface</li>
                    <li>Led and mentored a team of data scientists and engineers for a period of 12 months using Scrum.</li>
                    <li>Collaborated with cross-functional teams to design and implement solutions.</li>
                    <li>Key technologies used: Python, Transformers, Huggingface, PyTorch, Scikit-learn, Docker, AWS, SageMaker.</li>
                </ul>
            </div>
             <div class="job">
                <h3>Senior Data Scientist</h3>
                <p><strong>Philip Morris International - Contract</strong> | May 2020 – April 2021</p>
                <ul>
                    <li>Developed workforce planning models (attrition modelling and demand forecasting) for PMI’s global HR function. Key technologies used: Scikit-learn, Flask, Docker, Python, PySpark, Angular, Tableau.</li>
                </ul>
            </div>
             <div class="job">
                <h3>Senior Data Scientist</h3>
                <p><strong>Wellcome Collection - Contract</strong> | Feb 2020 - Apr 2020</p>
                <ul>
                    <li>Developed NLP pipeline for automatic document management system, including OCR, translation, named entity recognition, and document classification to speed up operations. Key technologies used: Python, Keras, Scikit-learn, GCP, Angular.</li>
                </ul>
            </div>
            <div class="job">
                <h3>Lead Data Scientist</h3>
                <p><strong>HSBC - Contract</strong> | Aug 2018 - Feb 2020</p>
                <ul>
                    <li>Developed and productionised anomaly detection models for HSBC Global Banking and Markets to monitor trades and improve risk compliance.</li>
                    <li>Provided guidance to business on how ML can be used and implemented to solve various business problems working closely with IT and Business teams.</li>
                    <li>Developed solutions using supervised and unsupervised ML methods to improve business operations.</li>
                    <li>Key technologies used: Python, Scikit-learn, Spark.</li>
                </ul>
            </div>
            <div class="job">
                <h3>Data Scientist</h3>
                <p><strong>Royal Mail - Contract</strong> | Jan 2018 - Aug 2018</p>
                <ul>
                    <li>Developed NLP solutions including sentiment analysis and unsupervised topic modelling for analysing messages on Royal Mail’s customer channels for the customer experience team. Key technologies used: Python, Keras, Tableau, Tensorflow, Docker, BERT.</li>
                    <li>Developed ML pipeline and models to give Royal Mail the ability to provide estimated delivery times for customers in the UK (https://www.youtube.com/watch?v=RpBsNQxBtU4). Key technologies used: Tensorflow, Keras, Scala, Spark, Zeppelin, MLlib, Docker, Python, Pandas, scikit-learn, Jupyter Notebooks.</li>
                </ul>
            </div>
            <div class="job">
                <h3>Data Scientist</h3>
                <p><strong>Vocalink/Mastercard - Full-time</strong> | Mar 2017 – Jan 2018</p>
                <ul>
                    <li>Account Profiling: Developed models using clustering methods (K-means, spectral clustering, DBCSAN, etc.) to profile accounts based on structured and unstructured data (Vocalink processes ~90% of UK salaries and ~70% of UK bill payments). The results were used in Vocalink’s fraud, anti-money-laundering and BI services. Key technologies used: Python, NLTK, Pandas, scikit-learn, Jupyter Notebooks, Seaborn.</li>
                    <li>Predictive analytics: Developed models to predict intraday credit and debit transaction volumes for major UK banks. This proof of concept was delivered to the Bank of England, as they required a tool to predict (and thereby prevent) likely debit cap breaches. Key technologies used: Python, Pandas, scikit-learn, Jupyter Notebooks, Keras, Tensorflow, Matplotlib, Seaborn.</li>
                </ul>
            </div>
            <div class="job">
                <h3>Data Scientist</h3>
                <p><strong>Deloitte - Full-time</strong> | Mar 2016 – Mar 2017</p>
                <ul>
                    <li>Predictive Analytics for Timetable Planning: Developed a predictive modelling tool for a national rail operator, improving network performance and reducing delays by over 15,000 minutes annually on a critical network subsection. Key technologies used: Python, Keras, Tensorflow, Pandas, Jupyter Notebooks, Tableau, AWS, Redshift.</li>
                    <li>Cost reduction analytics: Participated in data science initiatives to identify over £50M in projected cost savings over two years for a FTSE 100 pharmaceutical client by developing machine learning algorithms and analytic products. Key technologies used: Python, Pandas, scikit-learn, Jupyter Notebooks, Hive, Spark, Tableau.</li>
                    <li>Warranty analytics with NLP: Developed a proof of concept using machine learning and NLP to optimise warranty policies for a manufacturing client. Key technologies used: Python, NLTK, Latent Dirichlet Allocation, Jupyter Notebooks.</li>
                </ul>
            </div>
        </section>

        <section id="research">
            <h2>Research</h2>
            <h3>A Foundational Study of Predictive Coding Dynamics in Vision Transformers for Self-Supervised Learning</h3>
            <p><strong>Abstract:</strong> Self-supervised learning (SSL) has emerged as a powerful paradigm for learning visual representations without human labels, with Vision Transformers (ViTs) as a dominant architectural backbone. While modern SSL methods have achieved remarkable success, the principles of Predictive Coding (PC) offer a distinct, biologically-inspired framework for learning based on hierarchical latent prediction and local error minimization. This work introduces a model integrating PC principles with ViT architectures (PC-ViT), and provides a systematic, foundational study of its capabilities and challenges as an SSL model. We conduct a detailed empirical analysis of PC-ViT models, investigating the impact of model depth, width, and inference dynamics on the CIFAR-10 dataset. Our work establishes a crucial baseline, uncovering complex, non-monotonic scaling behaviors and a trade-off between reconstruction fidelity and feature quality. We demonstrate that with extensive tuning, PC-ViT can learn meaningful features, achieving a linear probing accuracy of up to 44.0% and approaching the performance of a standard Autoencoder baseline (45.0%), while still trailing more advanced SSL methods. This study provides a reproducible benchmark and a clear roadmap for future research into the unique optimization challenges of PC-Transformers.</p>
        </section>

        <section id="epistemology">
            <h2>Epistemology and AGI</h2>
            <p>My interest in epistemology, particularly the philosophy of Karl Popper and David Deutsch, informs my perspective on artificial general intelligence. I believe that understanding the principles of scientific discovery, such as falsifiability and the growth of knowledge, is crucial for navigating the path toward AGI. These ideas can help us identify and discard unpromising research directions and focus on approaches that are grounded in a valid theory of knowledge.</p>
        </section>

        <section id="education">
            <h2>Education</h2>
            <div class="education-item">
                <p><strong>Ph.D. in Cognitive Neuroscience</strong> | Saarland University | 2011 – 2015</p>
            </div>
            <div class="education-item">
                <p><strong>Machine Learning Engineer</strong> | Udacity | 2015 – 2016</p>
            </div>
            <div class="education-item">
                <p><strong>Deep Learning Nanodegree</strong> | Udacity | 2017 – 2018</p>
            </div>
        </section>
        
        <section id="certifications">
            <h2>Certifications and Training</h2>
            <ul>
                <li>2024: Building a GPU-Accelerated Retrieval Augmented Generation (RAG) Pipeline, Nvidia Deep Learning Institute</li>
                <li>2024: Large-Scale Production Deployment of RAG Pipelines, Nvidia Deep Learning Institute</li>
                <li>2024: Accelerated LLM Model Alignment and Deployment in NeMo, TensorRT-LLM, and Triton Inference Server, Nvidia Deep Learning Institute</li>
                <li>2024: Build AI Applications with GPU Vector Databases, Nvidia Deep Learning Institute</li>
                <li>2017 – 2018: Deep Learning Nanodegree, Udacity</li>
                <li>2015 – 2016: Machine Learning Engineer Nanodegree, Udacity</li>
                <li>2015: Neural Networks for Machine Learning, Coursera</li>
                <li>2015: Machine Learning, Coursera</li>
            </ul>
        </section>

        <section id="competitions">
            <h2>Kaggle Competitions</h2>
            <ul>
                <li>Insurance: Claims severity prediction for Allstate (2016).</li>
                <li>Manufacturing: Internal failure prediction for Bosch (2016).</li>
                <li>Retail: Sales forecasting for Rossmann (2015).</li>
                <li>Insurance: Risk classification for Prudential (2015-2016).</li>
            </ul>
        </section>

        <section id="conferences">
            <h2>Conferences</h2>
            <ul>
                <li>Nvidia GTC 2024, San Jose</li>
                <li>Open Data Science Conference, London, 2016.</li>
            </ul>
        </section>

    </div>
</body>
</html> 